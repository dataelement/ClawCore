#!/usr/bin/env node

import readline from "node:readline";
import path from "node:path";
import { fileURLToPath } from "node:url";
import chalk from "chalk";
import { loadConfig, saveConfig, resolveWorkspaceDir } from "./config/config.js";
import { createOpenAIProvider } from "./llm/provider.js";
import { Agent } from "./agent/agent.js";
import { initWorkspace } from "./workspace/init.js";

const __dirname = path.dirname(fileURLToPath(import.meta.url));
const TEMPLATE_DIR = path.resolve(__dirname, "../templates");

async function main() {
  const args = process.argv.slice(2);
  const workspaceArg = args.find((a) => a.startsWith("--workspace="))?.split("=")[1];
  const workspaceDir = resolveWorkspaceDir(workspaceArg);

  console.log(chalk.cyan.bold("\nðŸ¦ ClawCore") + chalk.dim(" â€” a core version of OpenClaw\n"));
  console.log(chalk.dim(`Workspace: ${workspaceDir}\n`));

  // Initialize workspace (creates directories + seeds templates if first run)
  await initWorkspace(workspaceDir, TEMPLATE_DIR);

  // Load config
  let config = await loadConfig(workspaceDir);

  // Check LLM config
  if (!config.llm.apiKey) {
    console.log(chalk.yellow("âš ï¸  No API key configured."));
    console.log(chalk.dim("  Set it via environment variable or config file:\n"));
    console.log(chalk.dim("  Option 1: export OPENAI_API_KEY=sk-..."));
    console.log(chalk.dim(`  Option 2: edit ${path.join(workspaceDir, "config.json")}\n`));

    // Try env var
    const envKey = process.env.OPENAI_API_KEY
      ?? process.env.CLAWCORE_API_KEY
      ?? process.env.LLM_API_KEY;

    if (envKey) {
      config = { ...config, llm: { ...config.llm, apiKey: envKey } };
      console.log(chalk.green("âœ“ API key found from environment variable.\n"));
    } else {
      // Interactive setup
      const rl = readline.createInterface({ input: process.stdin, output: process.stdout });
      const ask = (q: string) => new Promise<string>((r) => rl.question(q, r));

      const apiKey = await ask(chalk.cyan("Enter API key: "));
      if (!apiKey.trim()) {
        console.log(chalk.red("No API key provided. Exiting."));
        process.exit(1);
      }

      const baseUrl = await ask(
        chalk.cyan(`Base URL (default: ${config.llm.baseUrl}): `),
      );
      const model = await ask(
        chalk.cyan(`Model (default: ${config.llm.model}): `),
      );

      config = {
        ...config,
        llm: {
          apiKey: apiKey.trim(),
          baseUrl: baseUrl.trim() || config.llm.baseUrl,
          model: model.trim() || config.llm.model,
        },
      };

      await saveConfig(config);
      console.log(chalk.green("\nâœ“ Config saved.\n"));
      rl.close();
    }
  }

  // Create LLM provider
  const llm = createOpenAIProvider(config.llm);

  // Create agent with callbacks
  const agent = new Agent({
    llm,
    workspaceDir,
    callbacks: {
      onAssistantText: (text) => {
        if (text.trim() === "HEARTBEAT_OK") return; // silent
        console.log(chalk.green("\nðŸ¦ ") + text + "\n");
      },
      onToolCall: (name, args) => {
        console.log(
          chalk.dim(`  âš™ï¸  ${name}(${Object.entries(args).map(([k, v]) => `${k}=${JSON.stringify(v).slice(0, 60)}`).join(", ")})`),
        );
      },
      onToolResult: (name, result) => {
        if (result.length > 200) {
          console.log(chalk.dim(`  âœ“  ${name} â†’ ${result.slice(0, 200)}...`));
        } else {
          console.log(chalk.dim(`  âœ“  ${name} â†’ ${result}`));
        }
      },
      onHeartbeatStart: () => {
        console.log(chalk.dim("\nðŸ’“ Heartbeat scan...\n"));
      },
      onHeartbeatEnd: (result) => {
        console.log(chalk.dim(`ðŸ’“ ${result}\n`));
      },
    },
  });

  // Initialize agent
  await agent.init(config.heartbeat.enabled ? config.heartbeat.intervalMinutes : undefined);

  console.log(chalk.dim(`Model: ${config.llm.model}`));
  console.log("");
  console.log(chalk.cyan("ðŸ“– Quick Guide:"));
  console.log(chalk.dim("  â€¢ è¾“å…¥ exit æˆ– quit é€€å‡ºå¯¹è¯"));
  console.log(chalk.dim("  â€¢ æŠŠæ–‡ä»¶æ”¾å…¥ user/ æ–‡ä»¶å¤¹ï¼ŒAI å¯ä»¥å¸®ä½ é˜…è¯»å’Œåˆ†æž"));
  console.log(chalk.dim("  â€¢ è®© AIã€Œè®°ä½ã€æŸä»¶äº‹ï¼Œå®ƒä¼šè‡ªåŠ¨å†™å…¥ memory/ æ–‡ä»¶å¤¹"));
  console.log(chalk.dim("  â€¢ AI å¤„ç†ä»»åŠ¡æ—¶ä¼šåœ¨ workbench/ ä¸‹åˆ›å»ºä»»åŠ¡æ–‡ä»¶å¤¹"));
  console.log(chalk.dim("  â€¢ åœ¨ skills/ ä¸‹æ·»åŠ  SKILL.md å¯æ‰©å±• AI çš„èƒ½åŠ›"));
  console.log(chalk.dim("\n" + "â”€".repeat(60)) + "\n");

  // Interactive chat loop
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout,
    prompt: chalk.cyan("You: "),
  });

  rl.prompt();

  rl.on("line", async (line) => {
    const input = line.trim();
    if (!input) {
      rl.prompt();
      return;
    }

    if (input.toLowerCase() === "exit" || input.toLowerCase() === "quit") {
      console.log(chalk.dim("\nGoodbye! ðŸ¦\n"));
      agent.stop();
      rl.close();
      process.exit(0);
    }

    try {
      await agent.chat(input);
    } catch (err) {
      console.error(chalk.red(`\nError: ${err instanceof Error ? err.message : String(err)}\n`));
    }

    rl.prompt();
  });

  rl.on("close", () => {
    agent.stop();
    process.exit(0);
  });
}

main().catch((err) => {
  console.error(chalk.red(`Fatal: ${err.message}`));
  process.exit(1);
});
